{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# blackhole 改写NYC taxi票价预测  \n",
    "-------\n",
    "使用美国纽约 2009~2019年yellow出租车数据，全量数据75G左右，预测出租车行驶需要的票价。\n",
    "    \n",
    "原版实现地址：https://github.com/rapidsai-community/notebooks-contrib/blob/branch-0.12/intermediate_notebooks/E2E/taxi/NYCTaxi-E2E.ipynb  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blackhole环境准备\n",
    "**CodeLab平台默认不安装Blackhole，请先到导航左边“包管理”页面安装blackhole。**  \n",
    "**更多关于blackhole使用方法和案例，请参考[Blackhole简介和基本用法](https://cloud.baidu.com/doc/BML/s/9khemrnv7)。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "本案例选取2005年～2006年部分数据进行分析和训练，并且考虑到用户场景，我们准备了两份数据集：  \n",
    "小数据集: 抽样10000行，大小1.5M，让用户能够在本地端环境里，快速体验Blackhole。   \n",
    "大数据集: 大约7000万行，大小在10G左右，让用户通过端云同步，体验Blackhole处理大数据量过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-22 05:23:46--  https://codelab-dataset.cdn.bcebos.com/small/kaggle/taxi.zip\n",
      "Resolving codelab-dataset.cdn.bcebos.com (codelab-dataset.cdn.bcebos.com)... 123.125.132.35\n",
      "Connecting to codelab-dataset.cdn.bcebos.com (codelab-dataset.cdn.bcebos.com)|123.125.132.35|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 443110 (433K) [application/zip]\n",
      "Saving to: 'taxi.zip'\n",
      "\n",
      "taxi.zip            100%[===================>] 432.72K  --.-KB/s    in 0.09s   \n",
      "\n",
      "2021-04-22 05:23:46 (4.73 MB/s) - 'taxi.zip' saved [443110/443110]\n",
      "\n",
      "Archive:  taxi.zip\n",
      "   creating: taxi/\n",
      "  inflating: taxi/taxi_train.csv     \n",
      "  inflating: taxi/taxi_test.csv      \n"
     ]
    }
   ],
   "source": [
    "## 小数据量词表路径：https://codelab-dataset.cdn.bcebos.com/small/kaggle/taxi.zip\n",
    "## 大数据量词表路径：https://codelab-dataset.cdn.bcebos.com/full/kaggle/taxi.zip\n",
    "! wget https://codelab-dataset.cdn.bcebos.com/small/kaggle/taxi.zip && unzip -o taxi.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤1: 导入Blackhole依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import blackhole.dataframe as pd\n",
    "from blackhole.ml.model_selection import train_test_split\n",
    "from blackhole.ml.ensemble import RandomForestRegressor as bh_RandomForestRegressor\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤2 数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 160 ms, sys: 8.28 ms, total: 168 ms\n",
      "Wall time: 15.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dir = './taxi/'\n",
    "data_path = os.path.join(data_dir, \"taxi_train.csv\")\n",
    "train = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'blackhole.dataframe.frame.DataFrame'>\n",
      "Index: 9999 entries, 0 to 9998\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   VendorID               9999 non-null   int32  \n",
      " 1   tpep_pickup_datetime   9999 non-null   object \n",
      " 2   tpep_dropoff_datetime  9999 non-null   object \n",
      " 3   passenger_count        9999 non-null   int32  \n",
      " 4   trip_distance          9999 non-null   float64\n",
      " 5   pickup_longitude       9999 non-null   float64\n",
      " 6   pickup_latitude        9999 non-null   float64\n",
      " 7   RatecodeID             9999 non-null   int32  \n",
      " 8   store_and_fwd_flag     9999 non-null   object \n",
      " 9   dropoff_longitude      9999 non-null   float64\n",
      " 10  dropoff_latitude       9999 non-null   float64\n",
      " 11  payment_type           9999 non-null   int32  \n",
      " 12  fare_amount            9999 non-null   float64\n",
      " 13  extra                  9999 non-null   float64\n",
      " 14  mta_tax                9999 non-null   float64\n",
      " 15  tip_amount             9999 non-null   float64\n",
      " 16  tolls_amount           9999 non-null   float64\n",
      " 17  improvement_surcharge  9999 non-null   float64\n",
      " 18  total_amount           9999 non-null   float64\n",
      "dtypes: float64(12), int32(4), object(3)"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤3: 数据分析与处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, remap, must_haves):\n",
    "    \"\"\"data clean.\n",
    "\n",
    "    :param data: the origin data to be clean\n",
    "    :param remap: the remap column names\n",
    "    :param must_haves: the include column names\n",
    "    :return: the cleaned data\n",
    "    \"\"\"\n",
    "    # lowercase column names\n",
    "    tmp = {col: col.strip().lower() for col in list(data.columns)}\n",
    "    data = data.rename(columns=tmp)\n",
    "    # rename\n",
    "    data = data.rename(columns=remap)\n",
    "    # 清洗不需要的数据\n",
    "    for col in data.columns:\n",
    "        if col not in must_haves:\n",
    "            data = data.drop(col, axis=1)\n",
    "            continue\n",
    "\n",
    "        # 处理时间类型数据\n",
    "        if data[col].dtype == 'object' and col in ['pickup_datetime', 'dropoff_datetime']:\n",
    "            data[col] = data[col].astype('datetime64')\n",
    "            continue\n",
    "\n",
    "        # 数据类型类型（from string to float）& 缺失值处理（fillna）\n",
    "        if data[col].dtype == 'object':\n",
    "            data[col] = data[col].str.fillna('-1')\n",
    "            data[col] = data[col].astype('float32')\n",
    "        else:\n",
    "            # downcast from 64bit to 32bit\n",
    "            if 'int' in str(data[col].dtype):\n",
    "                data[col] = data[col].astype('int16')\n",
    "            if 'float' in str(data[col].dtype):\n",
    "                data[col] = data[col].astype('float32')\n",
    "            data[col] = data[col].fillna(-1)\n",
    "    return data\n",
    "\n",
    "def filter_outliers(data):\n",
    "    \"\"\"filter outliers.\n",
    "\n",
    "    :param data: the data to be filter\n",
    "    :return: the filtered data\n",
    "    \"\"\"\n",
    "    res = data[(data[\"fare_amount\"] > 0) & (data[\"fare_amount\"] < 500) & \n",
    "               (data[\"passenger_count\"] > 0) & (data[\"passenger_count\"] < 6) &\n",
    "               (data[\"pickup_longitude\"] != 0) & (data[\"pickup_latitude\"] != 0) & \n",
    "               (data[\"dropoff_longitude\"] != 0) & (data[\"dropoff_latitude\"] != 0)]\n",
    "    return res\n",
    "\n",
    "def haversine_distance_kernel(data):\n",
    "    \"\"\"\n",
    "    :param pickup_latitude: the pickup_latitude column\n",
    "    :param pickup_longitude: the pickup_longitude column\n",
    "    :param dropoff_latitude: the dropoff_latitude column\n",
    "    :param dropoff_longitude: the dropoff_longitude column\n",
    "    :param h_distance: the h_distance column\n",
    "    \"\"\"\n",
    "    x_1 = math.pi / 180 * data['pickup_latitude']\n",
    "    y_1 = math.pi / 180 * data['pickup_longitude']\n",
    "    x_2 = math.pi / 180 * data['dropoff_latitude']\n",
    "    y_2 = math.pi / 180 * data['dropoff_longitude']\n",
    "    dlon = y_2 - y_1\n",
    "    dlat = x_2 - x_1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(x_1) * np.cos(x_2) * np.sin(dlon / 2) ** 2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371\n",
    "    data['h_distance'] = c * r\n",
    "    return data\n",
    "\n",
    "\n",
    "def day_of_the_week_kernel(data):\n",
    "    \"\"\"\n",
    "    :param day: the day column from pickup_datetime\n",
    "    :param month: the month column from pickup_datetime\n",
    "    :param year: the year column from pickup_datetime\n",
    "    :param day_of_week: the day_of_week column\n",
    "    \"\"\"\n",
    "    shift = data['month'] if list(data['month'] < 3) else 0\n",
    "    Y = data['year'] - (data['month'] < 3)\n",
    "    y = Y - 2000\n",
    "    c = 20\n",
    "    d = data['day']\n",
    "    m = data['month'] + shift + 1\n",
    "    data['day_of_week'] = (d + np.floor(m * 2.6) + y + (y // 4) + (c // 4) - 2 * c) % 7\n",
    "    return data\n",
    "\n",
    "def add_features(data):\n",
    "    \"\"\"add new features.\n",
    "\n",
    "    :param data: the origin data to be added new features\n",
    "    :return: the whole data\n",
    "    \"\"\"\n",
    "    data['hour'] = data['pickup_datetime'].dt.hour.astype('int16')\n",
    "    data['year'] = data['pickup_datetime'].dt.year.astype('int16')\n",
    "    data['month'] = data['pickup_datetime'].dt.month.astype('int16')\n",
    "    data['day'] = data['pickup_datetime'].dt.day.astype('int16')\n",
    "    data = data.drop('pickup_datetime', axis=1)\n",
    "    data = data.drop('dropoff_datetime', axis=1)\n",
    "    data = haversine_distance_kernel(data)\n",
    "    data = day_of_the_week_kernel(data)\n",
    "    data['is_weekend'] = data['day_of_week'] < 2\n",
    "    data['is_weekend'] = data['is_weekend'].astype('int16')\n",
    "    data['passenger_count'] = data['passenger_count'].astype('int16')\n",
    "    data['rate_code'] = data['rate_code'].astype('int16')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 8.61 ms, total: 2.13 s\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "remap = {\n",
    "            'tpep_pickup_datetime': 'pickup_datetime',\n",
    "            'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "            'ratecodeid': 'rate_code',\n",
    "        }\n",
    "# 必需的columns & dtypes\n",
    "must_haves = {\n",
    "    'pickup_datetime': 'object',\n",
    "    'dropoff_datetime': 'object',\n",
    "    'passenger_count': 'int16',\n",
    "    'trip_distance': 'float32',\n",
    "    'pickup_longitude': 'float32',\n",
    "    'pickup_latitude': 'float32',\n",
    "    'rate_code': 'int16',\n",
    "    'dropoff_longitude': 'float32',\n",
    "    'dropoff_latitude': 'float32',\n",
    "    'fare_amount': 'float32',\n",
    "}\n",
    "# 数据清洗\n",
    "train = clean_data(train, remap, must_haves)\n",
    "# 过滤离群值\n",
    "train = filter_outliers(train)\n",
    "# 构造新特征\n",
    "train_data = add_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'blackhole.dataframe.frame.DataFrame'>\n",
      "Index: 9485 entries, 0 to 9998\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   passenger_count    9485 non-null   int16  \n",
      " 1   trip_distance      9485 non-null   float32\n",
      " 2   pickup_longitude   9485 non-null   float32\n",
      " 3   pickup_latitude    9485 non-null   float32\n",
      " 4   rate_code          9485 non-null   int16  \n",
      " 5   dropoff_longitude  9485 non-null   float32\n",
      " 6   dropoff_latitude   9485 non-null   float32\n",
      " 7   fare_amount        9485 non-null   float32\n",
      " 8   hour               9485 non-null   int16  \n",
      " 9   year               9485 non-null   int16  \n",
      " 10  month              9485 non-null   int16  \n",
      " 11  day                9485 non-null   int16  \n",
      " 12  h_distance         9485 non-null   float64\n",
      " 13  day_of_week        9485 non-null   float64\n",
      " 14  is_weekend         9485 non-null   int16  \n",
      "dtypes: float32(6), float64(2), int16(7)"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 150 ms, sys: 767 µs, total: 151 ms\n",
      "Wall time: 18.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = train_data[train_data.columns.difference(['fare_amount'])]\n",
    "y = train_data['fare_amount']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8536, 14), (8536,), (949, 14), (949,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤4: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "CPU times: user 30.6 s, sys: 818 ms, total: 31.4 s\n",
      "Wall time: 2.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {\n",
    "    'n_estimators': 20,\n",
    "    'max_depth': 12,\n",
    "    'mtries': 12,\n",
    "    'stopping_rounds': 2,\n",
    "    'stopping_tolerance': 0.01,\n",
    "    'stopping_metric': 'rmse',\n",
    "    \n",
    "}\n",
    "rf = bh_RandomForestRegressor(**params)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤5: 预测评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "drf prediction progress: |████████████████████████████████████████████████| 100%\n",
      "Export File progress: |███████████████████████████████████████████████████| 100%\n",
      "CPU times: user 6.49 s, sys: 378 ms, total: 6.87 s\n",
      "Wall time: 888 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from blackhole.ml.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def regressor_evaluate(y_true, y_pred):\n",
    "    \"\"\" regressor evaluate \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='variance_weighted')\n",
    "    return rmse, r2\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "rmse, r2 = regressor_evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.262973716501928, 0.8988329694941469)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤6: 导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blackhole.ml import save_model\n",
    "import shutil\n",
    "##云端执行时输出路径必须在环境变量“OUTPUT_PATH”下面\n",
    "output_path = os.getenv('OUTPUT_PATH', \"./\")  #输出路径\n",
    "model_path = os.path.join(output_path, 'bh_taxi_model') #模型保存路径\n",
    "# 判断模型路径是否存在，如果已存在删除并更新\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "save_model(rf, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
